{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FresUnet_DC_lightning",
      "provenance": [],
      "authorship_tag": "ABX9TyNdd7n99womvPCpdqKbeFHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darthwaydr007/attention-experiments/blob/main/FresUnet_DC_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfknfxEkQfG9"
      },
      "source": [
        "#!gdown https://drive.google.com/uc?id=1JV-_VxTaIcE3hIfmo10I3VPqkibHpuUp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irNLJT-5-hWf"
      },
      "source": [
        "#!unzip \"/content/crop_256.zip\" -d \"/content/sample_data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZV27kW_0m0p",
        "outputId": "28e9f169-5b21-4769-d24d-86c9be5739b3"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/5e/f4db2ff2416ff9a47bfc776e8f7601f419a4ea215745b5b800111f5da449/pytorch_lightning-1.1.2-py3-none-any.whl (671kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Collecting fsspec>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/80/72ac0982cc833945fada4b76c52f0f65435ba4d53bc9317d1c70b5f7e7d5/fsspec-0.8.5-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.7MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.19.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.7.0+cu101)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (51.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning) (0.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Building wheels for collected packages: PyYAML, future\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=050988f795cb44d7f89fc13688d243ab00b89b5112987fb74a159f8f316bb6ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=4ec16d1c4d46ee20f52da61d42ecee026b3dad6cdf1e4fd11176946c248613a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built PyYAML future\n",
            "Installing collected packages: fsspec, PyYAML, future, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 fsspec-0.8.5 future-0.18.2 pytorch-lightning-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBs4eIHSPDZZ"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import numpy\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.folder import IMG_EXTENSIONS\n",
        "from PIL import Image\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU available.' % torch.cuda.device_count())\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnquUpTpzaNM"
      },
      "source": [
        "## Install Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw2DIGNGzJui"
      },
      "source": [
        "import glob \n",
        "img_path_A = glob.glob(\"/content/sample_data/crop_256/train/A/*.png\")\n",
        "img_path_B = glob.glob(\"/content/sample_data/crop_256/train/B/*.png\")\n",
        "mask_path = glob.glob(\"/content/sample_data/crop_256/train/label/*.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd6zJ55CzL2w"
      },
      "source": [
        "img_path_A_valid = glob.glob(\"/content/sample_data/crop_256/val/A/*.png\")\n",
        "img_path_B_valid = glob.glob(\"/content/sample_data/crop_256/val/B/*.png\")\n",
        "mask_path_valid = glob.glob(\"/content/sample_data/crop_256/val/label/*.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je8BZYR-zN_P"
      },
      "source": [
        "img_path_A_test = glob.glob(\"/content/sample_data/crop_256/test/A/*.png\")\n",
        "img_path_B_test = glob.glob(\"/content/sample_data/crop_256/test/B/*.png\")\n",
        "mask_path_test = glob.glob(\"/content/sample_data/crop_256/test/label/*.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04adLy0wzPeS"
      },
      "source": [
        "imageA = Image.open(img_path_A[0])\n",
        "imageB = Image.open(img_path_B[0])\n",
        "mask = Image.open(mask_path[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqj5IAD8zSIX"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(imageA) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZjejM4DzTUG"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(imageB) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK3HD4YwzWFV"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(mask) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3jwemnRyoi"
      },
      "source": [
        "## Test IOU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeMMRKkcRxxc"
      },
      "source": [
        "test1 = Image.open(\"/content/sample_data/crop_256/test/label/test_71_15.png\")\n",
        "test2 = Image.open(\"/content/sample_data/crop_256/test/label/test_92_8.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KYYT-z-Tayv"
      },
      "source": [
        "trms = transforms.ToTensor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4apGzyfTosx"
      },
      "source": [
        "testA = trms(test1)\n",
        "testB = trms(test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYuAbsCMixrd"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(A[0,:,:]) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfyfNBQeiqFM"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(B[0,:,:]) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgpbZ50Aiz35"
      },
      "source": [
        "img_and = np.logical_and(A[0,:,:].numpy(), B[0,:,:].numpy()).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku-gAQYGTu25"
      },
      "source": [
        "img_or = np.logical_or(A[0,:,:].numpy(), B[0,:,:].numpy()).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQz3BLZjrrr"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(img_and) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa7C-Py6jtr1"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(img_or) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOGagWCvTypR"
      },
      "source": [
        "A = testA.unsqueeze(dim = 0)\n",
        "B = testB.unsqueeze(dim = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6tLOf3Xi1c"
      },
      "source": [
        "def meanIOU_single(predicted,target):\n",
        "    iousum = 0\n",
        "    for i in range(target.shape[0]):\n",
        "        target_arr = target[i, :, :].clone().detach().cpu().numpy()\n",
        "        predicted_arr = predicted[i, :, :].clone().detach().cpu().numpy()\n",
        "        \n",
        "        intersection = np.logical_and(target_arr, predicted_arr).sum()\n",
        "        union = np.logical_or(target_arr, predicted_arr).sum()\n",
        "        \n",
        "        iou_score = (intersection +1e-10) / (union+1e-10)\n",
        "        iousum +=iou_score\n",
        "        \n",
        "    miou = iousum/target.shape[0]\n",
        "    return torch.tensor(miou, dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYVWoWBLUAEF"
      },
      "source": [
        "meanIOU_single(B[:,:,:,:],A[:,:,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwMUj0EqK4Gs"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC2H6IIbK8ht"
      },
      "source": [
        "### FresUnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVLB5OUUK7wD"
      },
      "source": [
        "from torch.nn.modules.padding import ReplicationPad2d\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OJ7H60cLap9"
      },
      "source": [
        "class BasicBlock_ss(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, inplanes, planes = None, subsamp=1):\n",
        "        super(BasicBlock_ss, self).__init__()\n",
        "        if planes == None:\n",
        "            planes = inplanes * subsamp\n",
        "        self.conv1 = conv3x3(inplanes, planes)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.subsamp = subsamp\n",
        "        self.doit = planes != inplanes\n",
        "        if self.doit:\n",
        "            self.couple = nn.Conv2d(inplanes, planes, kernel_size=1)\n",
        "            self.bnc = nn.BatchNorm2d(planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.doit:\n",
        "            residual = self.couple(x)\n",
        "            residual = self.bnc(residual)\n",
        "        else:\n",
        "            residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        if self.subsamp > 1:\n",
        "            out = F.max_pool2d(out, kernel_size=self.subsamp, stride=self.subsamp)\n",
        "            residual = F.max_pool2d(residual, kernel_size=self.subsamp, stride=self.subsamp)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slmn-72sMUpG"
      },
      "source": [
        "class BasicBlock_us(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, inplanes, upsamp=1):\n",
        "        super(BasicBlock_us, self).__init__()\n",
        "        planes = int(inplanes / upsamp) # assumes integer result, fix later\n",
        "        self.conv1 = nn.ConvTranspose2d(inplanes, planes, kernel_size=3, padding=1, stride=upsamp, output_padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.upsamp = upsamp\n",
        "        self.couple = nn.ConvTranspose2d(inplanes, planes, kernel_size=3, padding=1, stride=upsamp, output_padding=1) \n",
        "        self.bnc = nn.BatchNorm2d(planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.couple(x)\n",
        "        residual = self.bnc(residual)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18fRqIiiMd3q"
      },
      "source": [
        "class FresUNet(pl.LightningModule):\n",
        "    \"\"\"FresUNet segmentation network.\"\"\"\n",
        "\n",
        "    def __init__(self, input_nbr, label_nbr):\n",
        "        \"\"\"Init FresUNet fields.\"\"\"\n",
        "        super(FresUNet, self).__init__()\n",
        "\n",
        "        self.input_nbr = input_nbr\n",
        "        \n",
        "        cur_depth = input_nbr\n",
        "        \n",
        "        base_depth = 16\n",
        "        \n",
        "        # Encoding stage 1\n",
        "        self.encres1_1 = BasicBlock_ss(cur_depth, planes = base_depth)\n",
        "        cur_depth = base_depth\n",
        "        d1 = base_depth\n",
        "        self.encres1_2 = BasicBlock_ss(cur_depth, subsamp=2)\n",
        "        cur_depth *= 2\n",
        "        \n",
        "        # Encoding stage 2\n",
        "        self.encres2_1 = BasicBlock_ss(cur_depth)\n",
        "        d2 = cur_depth\n",
        "        self.encres2_2 = BasicBlock_ss(cur_depth, subsamp=2)\n",
        "        cur_depth *= 2\n",
        "        \n",
        "        # Encoding stage 3\n",
        "        self.encres3_1 = BasicBlock_ss(cur_depth)\n",
        "        d3 = cur_depth\n",
        "        self.encres3_2 = BasicBlock_ss(cur_depth, subsamp=2)\n",
        "        cur_depth *= 2\n",
        "        \n",
        "        # Encoding stage 4\n",
        "        self.encres4_1 = BasicBlock_ss(cur_depth)\n",
        "        d4 = cur_depth\n",
        "        self.encres4_2 = BasicBlock_ss(cur_depth, subsamp=2)\n",
        "        cur_depth *= 2\n",
        "        # Decoding stage 4\n",
        "        self.decres4_1 = BasicBlock_ss(cur_depth)\n",
        "        self.decres4_2 = BasicBlock_us(cur_depth, upsamp=2)\n",
        "        cur_depth = int(cur_depth/2)\n",
        "        \n",
        "        # Decoding stage 3\n",
        "        self.decres3_1 = BasicBlock_ss(cur_depth + d4, planes = cur_depth)\n",
        "        self.decres3_2 = BasicBlock_us(cur_depth, upsamp=2)\n",
        "        cur_depth = int(cur_depth/2)\n",
        "        \n",
        "        # Decoding stage 2\n",
        "        self.decres2_1 = BasicBlock_ss(cur_depth + d3, planes = cur_depth)\n",
        "        self.decres2_2 = BasicBlock_us(cur_depth, upsamp=2)\n",
        "        cur_depth = int(cur_depth/2)\n",
        "        \n",
        "        # Decoding stage 1\n",
        "        self.decres1_1 = BasicBlock_ss(cur_depth + d2, planes = cur_depth)\n",
        "        self.decres1_2 = BasicBlock_us(cur_depth, upsamp=2)\n",
        "        cur_depth = int(cur_depth/2)\n",
        "        \n",
        "        # Output\n",
        "        self.coupling = nn.Conv2d(cur_depth + d1, label_nbr, kernel_size=1)\n",
        "        self.sm = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "        \n",
        "#         pad5 = ReplicationPad2d((0, x53.size(3) - x5d.size(3), 0, x53.size(2) - x5d.size(2)))\n",
        "        \n",
        "        s1_1 = x.size()\n",
        "        x1 = self.encres1_1(x)\n",
        "        x = self.encres1_2(x1)\n",
        "        \n",
        "        s2_1 = x.size()\n",
        "        x2 = self.encres2_1(x)\n",
        "        x = self.encres2_2(x2)\n",
        "        \n",
        "        s3_1 = x.size()\n",
        "        x3 = self.encres3_1(x)\n",
        "        x = self.encres3_2(x3)\n",
        "\n",
        "        s4_1 = x.size()\n",
        "        x4 = self.encres4_1(x)\n",
        "        x = self.encres4_2(x4)\n",
        "        \n",
        "        x = self.decres4_1(x)\n",
        "        x = self.decres4_2(x)\n",
        "        s4_2 = x.size()\n",
        "        pad4 = ReplicationPad2d((0, s4_1[3] - s4_2[3], 0, s4_1[2] - s4_2[2]))\n",
        "        x = pad4(x)\n",
        "        \n",
        "        # x = self.decres3_1(x)\n",
        "        x = self.decres3_1(torch.cat((x, x4), 1))\n",
        "        x = self.decres3_2(x)\n",
        "        s3_2 = x.size()\n",
        "        pad3 = ReplicationPad2d((0, s3_1[3] - s3_2[3], 0, s3_1[2] - s3_2[2]))\n",
        "        x = pad3(x)\n",
        "        \n",
        "        x = self.decres2_1(torch.cat((x, x3), 1))\n",
        "        x = self.decres2_2(x)\n",
        "        s2_2 = x.size()\n",
        "        pad2 = ReplicationPad2d((0, s2_1[3] - s2_2[3], 0, s2_1[2] - s2_2[2]))\n",
        "        x = pad2(x)\n",
        "        \n",
        "        x = self.decres1_1(torch.cat((x, x2), 1))\n",
        "        x = self.decres1_2(x)\n",
        "        s1_2 = x.size()\n",
        "        pad1 = ReplicationPad2d((0, s1_1[3] - s1_2[3], 0, s1_1[2] - s1_2[2]))\n",
        "        x = pad1(x)\n",
        "        \n",
        "        x = self.coupling(torch.cat((x, x1), 1))\n",
        "        #x = self.sm(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgnYgoSBK_Ng"
      },
      "source": [
        "### Unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86XlNJVaLBqD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx0BM8UFLCwc"
      },
      "source": [
        "### SiameseUnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pSFfk1BLGIy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62M9yRw5zdpd"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elHbtXA87-Zp"
      },
      "source": [
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksw9J1r74vrQ"
      },
      "source": [
        "class LEVIRDataset(Dataset):\n",
        "  def __init__(self , img_path_A, img_path_B, mask_path):\n",
        "    self.img_path_A = img_path_A\n",
        "    self.img_path_B = img_path_B\n",
        "    self.mask_path = mask_path\n",
        "    self.length = len(self.img_path_A)\n",
        "    self.transforms = transforms.Compose([\n",
        "                                          transforms.ToTensor()])\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self , index):   \n",
        "    return {\n",
        "        'imgA' : self.transforms(Image.open(self.img_path_A[index])) , \n",
        "        'imgB' : self.transforms(Image.open(self.img_path_B[index])) ,\n",
        "        'mask' : self.transforms(Image.open(self.mask_path[index])) , \n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YCT07KDziLp"
      },
      "source": [
        "class LEVIRDateModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, batch_size):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def setup(self):\n",
        "    self.train_dataset = LEVIRDataset(img_path_A ,img_path_B, mask_path)\n",
        "    self.valid_dataset = LEVIRDataset(img_path_A_valid ,img_path_B_valid, mask_path_valid)\n",
        "    self.test_dataset = LEVIRDataset(img_path_A_test ,img_path_B_test, mask_path_test)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "      return DataLoader(self.valid_dataset, batch_size=self.batch_size)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "      return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWXVc1EyCCq-"
      },
      "source": [
        "data_module = LEVIRDateModule(batch_size = 16)\n",
        "data_module.setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZl3PNWZLGmo"
      },
      "source": [
        "## Optimiiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QukK-fW7qm_J"
      },
      "source": [
        "from pytorch_lightning import Trainer, seed_everything\n",
        "seed_everything(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoVTkaxgLbAH"
      },
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDd6gygJiZII"
      },
      "source": [
        "from pytorch_lightning.metrics import Metric\n",
        "\n",
        "class IOU(Metric):\n",
        "    def __init__(self, dist_sync_on_step=False):\n",
        "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
        "\n",
        "        self.add_state(\"iou\", default=torch.tensor(0, dtype = torch.float), dist_reduce_fx=\"sum\")\n",
        "        self.add_state(\"count\", default=torch.tensor(0 , dtype = torch.float), dist_reduce_fx=\"sum\")\n",
        "\n",
        "    def update(self, preds, target):\n",
        "        #preds, target = self._input_format(preds, target)\n",
        "        #assert preds.shape == target.shape\n",
        "        self.iou += meanIOU_single(preds,target)\n",
        "        self.count += 1\n",
        "\n",
        "    def compute(self):\n",
        "        return self.iou / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHXGiLCAMxKG"
      },
      "source": [
        "class Model(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = FresUNet(3*2, 2)\n",
        "    self.train_iou = IOU()\n",
        "    self.valid_iou = IOU()\n",
        "\n",
        "  \n",
        "  def forward(self, imgA , imgB):\n",
        "    out = self.model(imgA , imgB)\n",
        "    return out\n",
        "\n",
        "  #def cross_entropy_loss(self, logits, labels):\n",
        "  #  return nn.CrossEntropyLoss(logits, labels)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.5, 0.999), weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
        "    return optimizer , scheduler\n",
        "\n",
        "  #def training_step_end(self, batch_parts):\n",
        "  #  gpu_0_prediction = batch_parts[0]['pred']\n",
        "  #  gpu_1_prediction = batch_parts[1]['pred']\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    imgA = batch['imgA']\n",
        "    imgB = batch['imgB']\n",
        "    mask1 = batch['mask']\n",
        "    label = mask1[:,0,:,:]\n",
        "    label[label>0] = 1\n",
        "    label = label.long()\n",
        "\n",
        "    output = self.model(imgA , imgB)\n",
        "    loss = criterion(output , label)\n",
        "\n",
        "    labelx = mask1[:,0,:,:]\n",
        "    preds = sigmoid(output)\n",
        "    preds[preds>=0.5] = 1\n",
        "    preds[preds<0.5] = 0\n",
        "\n",
        "    #iou = meanIOU_single(labelx, preds[:,1,:,:])\n",
        "    self.train_iou(preds[:,1,:,:].long(), labelx.long())\n",
        "    self.log('train_iou', self.train_iou, on_step=True, on_epoch=True , prog_bar=True, logger=True)\n",
        "    self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    imgA = batch['imgA']\n",
        "    imgB = batch['imgB']\n",
        "    mask1 = batch['mask']\n",
        "    label = mask1[:,0,:,:]\n",
        "    label[label>0] = 1\n",
        "    label = label.long()\n",
        "\n",
        "    output = self.model(imgA , imgB)\n",
        "    loss = criterion(output , label)\n",
        "\n",
        "    labelx = mask1[:,0,:,:]\n",
        "    preds = sigmoid(output)\n",
        "    preds[preds>=0.5] = 1\n",
        "    preds[preds<0.5] = 0\n",
        "\n",
        "\n",
        "    #iou = meanIOU_single(labelx, preds[:,1,:,:])\n",
        "    self.valid_iou(preds[:,1,:,:], labelx)\n",
        "    self.log('valid_iou', self.valid_iou, on_step=True, on_epoch=True , prog_bar=True, logger=True)\n",
        "    self.log('valid_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh7o69ordA6W"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzlK7syPZ2f2"
      },
      "source": [
        "trainer = pl.Trainer(gpus=1 , precision = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu95jg4nbDjN"
      },
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDsO1z82dfYX"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}